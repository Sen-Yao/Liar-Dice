# RL Specialized Models - ä¸“ç”¨æ¨¡å‹å¼ºåŒ–å­¦ä¹ 

## ğŸ“– æ¦‚è¿°

è¿™ä¸ªæ¨¡å—å®ç°äº†é’ˆå¯¹ä¸åŒç©å®¶æ•°é‡ï¼ˆ2-6äººï¼‰çš„ä¸“ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡å‹ã€‚ä¸é€šç”¨æ¨¡å‹ä¸åŒï¼Œä¸“ç”¨æ¨¡å‹ä¸ºæ¯ç§ç©å®¶é…ç½®è®­ç»ƒç‹¬ç«‹çš„ç¥ç»ç½‘ç»œï¼Œä»¥è·å¾—æœ€ä¼˜çš„æ€§èƒ½è¡¨ç°ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒæ€æƒ³
- **ä¸“ç”¨ä¼˜åŒ–**ï¼šæ¯ä¸ªç©å®¶æ•°é‡ä½¿ç”¨ç‹¬ç«‹çš„åŠ¨ä½œç©ºé—´å’Œæ¨¡å‹
- **é«˜æ•ˆè®­ç»ƒ**ï¼šåŠ¨ä½œç©ºé—´ç²¾ç¡®åŒ¹é…æ¸¸æˆé…ç½®ï¼Œå‡å°‘æ— æ•ˆåŠ¨ä½œ
- **æ€§èƒ½æœ€ä¼˜**ï¼šé’ˆå¯¹ç‰¹å®šåœºæ™¯æ·±åº¦ä¼˜åŒ–ï¼Œé¿å…é€šç”¨æ¨¡å‹çš„å¤æ‚æ€§

### ç›®å½•ç»“æ„

```
rl_specialized/
â”œâ”€â”€ action_spaces/          # åŠ¨ä½œç©ºé—´å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py            # åŠ¨ä½œç©ºé—´åŸºç¡€æŠ½è±¡ç±»
â”‚   â””â”€â”€ player_specific.py # ä¸“ç”¨æ¨¡å‹åŠ¨ä½œç©ºé—´å®ç°
â”œâ”€â”€ agents/                # RLæ™ºèƒ½ä½“å®ç°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ specialized_agent.py (å¾…å®ç°)
â”œâ”€â”€ networks/              # ç¥ç»ç½‘ç»œç»“æ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ policy_network.py (å¾…å®ç°)
â”œâ”€â”€ training/              # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ train_specialized.py (å¾…å®ç°)
â”œâ”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ state_encoder.py  # çŠ¶æ€ç¼–ç å™¨
â””â”€â”€ README.md             # æœ¬æ–‡ä»¶
```

## ğŸ¯ åŠ¨ä½œç©ºé—´è®¾è®¡

### åŠ¨ä½œæ˜ å°„è§„åˆ™

ä¸“ç”¨æ¨¡å‹çš„åŠ¨ä½œç©ºé—´é‡‡ç”¨ç®€æ´é«˜æ•ˆçš„IDæ˜ å°„ï¼š

```python
# åŠ¨ä½œç©ºé—´å¤§å°è®¡ç®—ï¼ˆä»¥2äººæ¸¸æˆä¸ºä¾‹ï¼‰
max_dice = 2 * 5 = 10
total_actions = 1 + (2 * 10 * 6) = 121

# åŠ¨ä½œIDåˆ†é…ï¼š
- Challenge: action_id = 0
- æ–‹æ¨¡å¼çŒœæµ‹: action_id = 1 + (count-1)*6 + (face-1)
- é£æ¨¡å¼çŒœæµ‹: action_id = 1 + 60 + (count-1)*6 + (face-1)
```

### ä¸åŒç©å®¶æ•°é‡çš„åŠ¨ä½œç©ºé—´å¤§å°

| ç©å®¶æ•°é‡ | æœ€å¤§éª°å­æ•° | åŠ¨ä½œç©ºé—´å¤§å° | å†…å­˜å ç”¨ |
|---------|-----------|-------------|---------|
| 2äºº     | 10        | 121         | æœ€å°    |
| 3äºº     | 15        | 181         | å°      |
| 4äºº     | 20        | 241         | ä¸­ç­‰    |
| 5äºº     | 25        | 301         | è¾ƒå¤§    |
| 6äºº     | 30        | 361         | æœ€å¤§    |

## ğŸ§  æ ¸å¿ƒç»„ä»¶

### 1. BaseActionSpace (base.py)
- æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰åŠ¨ä½œç©ºé—´çš„é€šç”¨æ¥å£
- å®ç°æ¸¸æˆè§„åˆ™éªŒè¯é€»è¾‘
- æä¾›è·¨æ¨¡å¼æ¯”è¾ƒç®—æ³•

### 2. PlayerSpecificActionSpace (player_specific.py)
- ä¸“ç”¨æ¨¡å‹çš„å…·ä½“å®ç°
- é«˜æ•ˆçš„åŠ¨ä½œIDä¸å¯¹è±¡äº’è½¬
- åˆæ³•åŠ¨ä½œæ©ç ç”Ÿæˆ
- é¢„å®šä¹‰2-6äººæ¸¸æˆé…ç½®

### 3. StateEncoder (state_encoder.py)
- å°†å¤æ‚æ¸¸æˆçŠ¶æ€ç¼–ç ä¸ºç¥ç»ç½‘ç»œè¾“å…¥
- å›ºå®šé•¿åº¦ç‰¹å¾å‘é‡ï¼šæ‰‹ç‰Œ(6) + ç©å®¶ä¿¡æ¯(n) + çŒœæµ‹(4) + æ¸¸æˆçŠ¶æ€(3)
- æ”¯æŒæ‰¹é‡ç¼–ç å’Œç‰¹å¾åç§°æ˜ å°„

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åˆ›å»º2äººæ¸¸æˆåŠ¨ä½œç©ºé—´

```python
from rl_specialized.action_spaces import get_2_player_action_space

# åˆ›å»ºä¸“ç”¨åŠ¨ä½œç©ºé—´
action_space = get_2_player_action_space()

# è·å–åŠ¨ä½œç©ºé—´ä¿¡æ¯
print(f"åŠ¨ä½œç©ºé—´å¤§å°: {action_space.get_action_space_size()}")
print(f"åˆ†å¸ƒä¿¡æ¯: {action_space.get_action_distribution_info()}")

# åŠ¨ä½œè½¬æ¢
action_id = 5
action_obj = action_space.id_to_action(action_id)
print(f"åŠ¨ä½œID {action_id} -> {action_obj}")

# è·å–åˆæ³•åŠ¨ä½œæ©ç 
observation = {...}  # æ¥è‡ªç¯å¢ƒçš„è§‚å¯Ÿ
mask = action_space.get_action_mask(observation)
valid_actions = action_space.get_valid_actions(observation)
```

### çŠ¶æ€ç¼–ç 

```python
from rl_specialized.utils import create_state_encoder

# åˆ›å»ºçŠ¶æ€ç¼–ç å™¨
encoder = create_state_encoder(num_players=2)

# ç¼–ç å•ä¸ªè§‚å¯Ÿ
observation = {...}  # æ¥è‡ªç¯å¢ƒ
encoded_state = encoder.encode_observation(observation)
print(f"ç¼–ç åçŠ¶æ€ç»´åº¦: {encoded_state.shape}")

# æ‰¹é‡ç¼–ç 
observations = [obs1, obs2, obs3]
batch_states = encoder.encode_batch(observations)
```

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

### ä¼˜åŠ¿
- **å†…å­˜æ•ˆç‡**ï¼šåŠ¨ä½œç©ºé—´é’ˆå¯¹ç‰¹å®šç©å®¶æ•°é‡æœ€å°åŒ–
- **è®­ç»ƒé€Ÿåº¦**ï¼šå‡å°‘æ— æ•ˆåŠ¨ä½œæ¢ç´¢ï¼ŒåŠ å¿«æ”¶æ•›
- **æ¨¡å‹ç²¾åº¦**ï¼šä¸“é—¨ä¼˜åŒ–ï¼Œé¿å…é€šç”¨æ¨¡å‹çš„æ€§èƒ½å¦¥å
- **å¯è§£é‡Šæ€§**ï¼šæ¯ä¸ªæ¨¡å‹å¯¹åº”æ˜ç¡®çš„æ¸¸æˆé…ç½®

### é€‚ç”¨åœºæ™¯
- å›ºå®šç©å®¶æ•°é‡çš„æ¸¸æˆç¯å¢ƒ
- å¯¹æ€§èƒ½è¦æ±‚æé«˜çš„ç”Ÿäº§ç¯å¢ƒ
- éœ€è¦è¯¦ç»†åˆ†æç‰¹å®šé…ç½®çš„ç ”ç©¶åœºæ™¯
- èµ„æºå……è¶³ï¼Œå¯ä»¥ç»´æŠ¤å¤šä¸ªæ¨¡å‹çš„æƒ…å†µ

## ğŸ”§ å¼€å‘æŒ‡å—

### æ‰©å±•æ–°ç©å®¶æ•°é‡

å¦‚éœ€æ”¯æŒ7äººæˆ–æ›´å¤šç©å®¶ï¼š

1. åœ¨ `player_specific.py` ä¸­æ·»åŠ æ–°çš„å·¥å‚å‡½æ•°
2. æ›´æ–° `__init__.py` å¯¼å‡ºæ–°å‡½æ•°
3. éªŒè¯åŠ¨ä½œç©ºé—´å¤§å°å’Œå†…å­˜å ç”¨

### è‡ªå®šä¹‰çŠ¶æ€ç¼–ç 

StateEncoderæ”¯æŒç»§æ‰¿å’Œè‡ªå®šä¹‰ï¼š

```python
class CustomStateEncoder(StateEncoder):
    def encode_observation(self, observation):
        # æ·»åŠ è‡ªå®šä¹‰ç‰¹å¾
        base_features = super().encode_observation(observation)
        custom_features = self._extract_custom_features(observation)
        return np.concatenate([base_features, custom_features])
```

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### åŠ¨ä½œç©ºé—´éªŒè¯

```python
# éªŒè¯åŠ¨ä½œæ˜ å°„çš„åŒå‘ä¸€è‡´æ€§
action_space = get_2_player_action_space()
for action_id in range(action_space.get_action_space_size()):
    action_obj = action_space.id_to_action(action_id)
    recovered_id = action_space.action_to_id(action_obj)
    assert action_id == recovered_id
```

### æ©ç æ­£ç¡®æ€§æµ‹è¯•

```python
# æµ‹è¯•åˆæ³•åŠ¨ä½œæ©ç 
observation = create_test_observation()
mask = action_space.get_action_mask(observation)
for action_id in range(len(mask)):
    if mask[action_id]:
        action_obj = action_space.id_to_action(action_id)
        assert is_legal_in_game_context(action_obj, observation)
```

## ğŸ“ˆ ä¸‹ä¸€æ­¥è®¡åˆ’

1. **å®ç°SpecializedAgentç±»** - åŸºäºä¸“ç”¨åŠ¨ä½œç©ºé—´çš„RLæ™ºèƒ½ä½“
2. **è®¾è®¡PolicyNetwork** - é’ˆå¯¹ä¸åŒç©å®¶æ•°é‡ä¼˜åŒ–çš„ç½‘ç»œç»“æ„
3. **å¼€å‘è®­ç»ƒè„šæœ¬** - æ”¯æŒå¹¶è¡Œè®­ç»ƒå¤šä¸ªä¸“ç”¨æ¨¡å‹
4. **æ€§èƒ½å¯¹æ¯”å®éªŒ** - ä¸é€šç”¨æ¨¡å‹çš„è¯¦ç»†æ€§èƒ½å¯¹æ¯”
5. **æ¨¡å‹èåˆç­–ç•¥** - æ¢ç´¢å¤šæ¨¡å‹é›†æˆçš„å¯èƒ½æ€§

## ğŸ¤ è´¡çŒ®æŒ‡å—

- éµå¾ªé¡¹ç›®ç¼–ç è§„èŒƒï¼šè‹±æ–‡å‘½å + ä¸­æ–‡æ³¨é‡Š
- ä¿æŒä»£ç ç®€æ´æ˜äº†ï¼Œé¿å…è¿‡åº¦è®¾è®¡
- æ·»åŠ å……åˆ†çš„å•å…ƒæµ‹è¯•å’Œæ–‡æ¡£
- æ€§èƒ½ä¼˜åŒ–æ—¶ä¿æŒä»£ç å¯è¯»æ€§

---

*æœ€åæ›´æ–°: 2024å¹´9æœˆ22æ—¥*
*ç‰ˆæœ¬: v1.0.0*
*ä½œè€…: éª°å­éª—å­RLé¡¹ç›®ç»„*